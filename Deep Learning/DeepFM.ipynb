{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepFM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D_hWFlBTzTD"
      },
      "source": [
        "This is an example of how we can apply DeepFM using 'deepctr' to solve a binary classification problem.\n",
        "\n",
        "We will utilize the frappe dataset (https://www.baltrunas.info/context-aware).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vpsd4m3fuXB"
      },
      "source": [
        "# Imports and Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El-GyEbI38Qh",
        "outputId": "ba18134d-1c5d-434e-aaa5-a692d9dd307f"
      },
      "source": [
        "!pip install deepctr==0.7.5"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepctr==0.7.5 in /usr/local/lib/python3.7/dist-packages (0.7.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from deepctr==0.7.5) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from deepctr==0.7.5) (2.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr==0.7.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr==0.7.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr==0.7.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr==0.7.5) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->deepctr==0.7.5) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py->deepctr==0.7.5) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqlbTMHA3nQg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "import os \n",
        "from deepctr.models import *\n",
        "from deepctr.inputs import  SparseFeat, DenseFeat, get_feature_names\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PG1SRyJfyeU"
      },
      "source": [
        "\n",
        "# Mount google drive\n",
        "from google.colab import drive"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0roCUQKGfvcT"
      },
      "source": [
        "# Mount Drive and change paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBqlrhGtf0By",
        "outputId": "6aa3da29-335f-4547-bbee-f0b8c85deb87"
      },
      "source": [
        "#Mount Drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_oerE1tf2Bi"
      },
      "source": [
        "#Make sure you downloaded the dataset and you create such a path, alternativly - changed this path\n",
        "DATA_PATH = '/content/drive/My Drive/Recommender Systems/Datasets/'\n",
        "os.chdir(DATA_PATH)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WozBDG0XgDVM"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "J2LIY6nB3-xZ",
        "outputId": "1ac76d5a-9f35-446c-96e6-abd5a37366be"
      },
      "source": [
        "data = pd.read_csv('frappe_all.csv')\n",
        "data['label'] *= 1.0\n",
        "data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>daytime</th>\n",
              "      <th>weekday</th>\n",
              "      <th>isweekend</th>\n",
              "      <th>homework</th>\n",
              "      <th>cost</th>\n",
              "      <th>weather</th>\n",
              "      <th>country</th>\n",
              "      <th>city</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66</td>\n",
              "      <td>2471</td>\n",
              "      <td>morning</td>\n",
              "      <td>sunday</td>\n",
              "      <td>weekend</td>\n",
              "      <td>unknown</td>\n",
              "      <td>free</td>\n",
              "      <td>rainy</td>\n",
              "      <td>United States</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>269</td>\n",
              "      <td>116</td>\n",
              "      <td>afternoon</td>\n",
              "      <td>thursday</td>\n",
              "      <td>weekend</td>\n",
              "      <td>unknown</td>\n",
              "      <td>paid</td>\n",
              "      <td>sunny</td>\n",
              "      <td>Palestine</td>\n",
              "      <td>434</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>225</td>\n",
              "      <td>354</td>\n",
              "      <td>noon</td>\n",
              "      <td>saturday</td>\n",
              "      <td>workday</td>\n",
              "      <td>unknown</td>\n",
              "      <td>free</td>\n",
              "      <td>stormy</td>\n",
              "      <td>Hungary</td>\n",
              "      <td>347</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>108</td>\n",
              "      <td>5</td>\n",
              "      <td>sunset</td>\n",
              "      <td>wednesday</td>\n",
              "      <td>workday</td>\n",
              "      <td>home</td>\n",
              "      <td>free</td>\n",
              "      <td>drizzle</td>\n",
              "      <td>Japan</td>\n",
              "      <td>391</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>257</td>\n",
              "      <td>33</td>\n",
              "      <td>morning</td>\n",
              "      <td>thursday</td>\n",
              "      <td>workday</td>\n",
              "      <td>unknown</td>\n",
              "      <td>free</td>\n",
              "      <td>cloudy</td>\n",
              "      <td>United States</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288604</th>\n",
              "      <td>133</td>\n",
              "      <td>28</td>\n",
              "      <td>evening</td>\n",
              "      <td>friday</td>\n",
              "      <td>weekend</td>\n",
              "      <td>unknown</td>\n",
              "      <td>free</td>\n",
              "      <td>snowy</td>\n",
              "      <td>Finland</td>\n",
              "      <td>1009</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288605</th>\n",
              "      <td>583</td>\n",
              "      <td>2445</td>\n",
              "      <td>afternoon</td>\n",
              "      <td>friday</td>\n",
              "      <td>workday</td>\n",
              "      <td>unknown</td>\n",
              "      <td>free</td>\n",
              "      <td>unknown</td>\n",
              "      <td>unknown</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288606</th>\n",
              "      <td>264</td>\n",
              "      <td>16</td>\n",
              "      <td>sunrise</td>\n",
              "      <td>tuesday</td>\n",
              "      <td>weekend</td>\n",
              "      <td>home</td>\n",
              "      <td>free</td>\n",
              "      <td>snowy</td>\n",
              "      <td>Lebanon</td>\n",
              "      <td>306</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288607</th>\n",
              "      <td>70</td>\n",
              "      <td>336</td>\n",
              "      <td>sunrise</td>\n",
              "      <td>tuesday</td>\n",
              "      <td>workday</td>\n",
              "      <td>unknown</td>\n",
              "      <td>free</td>\n",
              "      <td>sleet</td>\n",
              "      <td>Japan</td>\n",
              "      <td>919</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288608</th>\n",
              "      <td>154</td>\n",
              "      <td>16</td>\n",
              "      <td>morning</td>\n",
              "      <td>friday</td>\n",
              "      <td>workday</td>\n",
              "      <td>unknown</td>\n",
              "      <td>free</td>\n",
              "      <td>unknown</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>392</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>288609 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        user  item    daytime    weekday  ...  weather         country  city label\n",
              "0         66  2471    morning     sunday  ...    rainy   United States     0   1.0\n",
              "1        269   116  afternoon   thursday  ...    sunny       Palestine   434   0.0\n",
              "2        225   354       noon   saturday  ...   stormy         Hungary   347   0.0\n",
              "3        108     5     sunset  wednesday  ...  drizzle           Japan   391   0.0\n",
              "4        257    33    morning   thursday  ...   cloudy   United States     0   1.0\n",
              "...      ...   ...        ...        ...  ...      ...             ...   ...   ...\n",
              "288604   133    28    evening     friday  ...    snowy         Finland  1009   0.0\n",
              "288605   583  2445  afternoon     friday  ...  unknown         unknown     0   1.0\n",
              "288606   264    16    sunrise    tuesday  ...    snowy         Lebanon   306   0.0\n",
              "288607    70   336    sunrise    tuesday  ...    sleet           Japan   919   0.0\n",
              "288608   154    16    morning     friday  ...  unknown  United Kingdom   392   1.0\n",
              "\n",
              "[288609 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDC26vl-gJRc",
        "outputId": "8d19b180-b03a-4d60-b266-8728729a5029"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 288609 entries, 0 to 288608\n",
            "Data columns (total 11 columns):\n",
            " #   Column     Non-Null Count   Dtype  \n",
            "---  ------     --------------   -----  \n",
            " 0   user       288609 non-null  int64  \n",
            " 1   item       288609 non-null  int64  \n",
            " 2   daytime    288609 non-null  object \n",
            " 3   weekday    288609 non-null  object \n",
            " 4   isweekend  288609 non-null  object \n",
            " 5   homework   288609 non-null  object \n",
            " 6   cost       288609 non-null  object \n",
            " 7   weather    288609 non-null  object \n",
            " 8   country    288609 non-null  object \n",
            " 9   city       288609 non-null  int64  \n",
            " 10  label      288609 non-null  float64\n",
            "dtypes: float64(1), int64(3), object(7)\n",
            "memory usage: 24.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvVUvvqlgTkq"
      },
      "source": [
        "## Define dense and sparse features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23NoHNra4ikx"
      },
      "source": [
        "sparse_features = ['user', 'item', 'daytime', 'weekday', 'isweekend', 'homework', 'cost',\n",
        "       'weather', 'country', 'city']\n",
        "dense_features = []\n",
        "\n",
        "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
        "data[dense_features] = data[dense_features].fillna(0, )\n",
        "target = ['label']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLTmTFg2gZUR"
      },
      "source": [
        "At the moment all features are defined as sparse. As a code task, use alternative data (e.g., Crieto, Avazu, etc') or enrich this data with additional dense features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV-L8b2S47Co"
      },
      "source": [
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"        \n",
        "        \n",
        "        # for unique_item in data_list.unique():\n",
        "        #     if unique_item not in self.label_encoder.classes_:\n",
        "        #         new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "        new_data_list = data_list.apply(lambda x: 'Unknown' if x not in self.label_encoder.classes_ else x)        \n",
        "        return self.label_encoder.transform(new_data_list)    "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYM3Xu32hLrR"
      },
      "source": [
        "In order to use encoding we first have to split the data intro train/validation/test sets. \n",
        "\n",
        "Motivation: we do not want to encode data of the training set utilizing data from the test set for example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQd5Ybd04JyJ"
      },
      "source": [
        "train, test = train_test_split(data, test_size=0.1)\n",
        "train, val = train_test_split(data, test_size=0.2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZkv0Qt_4yzx",
        "outputId": "8a4fd5f4-8f95-4682-a3a8-038d84a3aeda"
      },
      "source": [
        "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
        "for feat in tqdm(sparse_features):\n",
        "    lbe = LabelEncoderExt()\n",
        "    lbe.fit(train[feat])    \n",
        "    print('finished fitting')\n",
        "    train[feat] = lbe.transform(train[feat])\n",
        "    print('finished transform train')\n",
        "    val[feat] = lbe.transform(val[feat])\n",
        "    print('finished transform validation')\n",
        "    test[feat] = lbe.transform(test[feat])\n",
        "    print('finished transform test')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished fitting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform validation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "\r 10%|█         | 1/10 [00:02<00:25,  2.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform test\n",
            "finished fitting\n",
            "finished transform train\n",
            "finished transform validation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:05<00:22,  2.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform test\n",
            "finished fitting\n",
            "finished transform train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:07<00:16,  2.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform validation\n",
            "finished transform test\n",
            "finished fitting\n",
            "finished transform train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:08<00:12,  2.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform validation\n",
            "finished transform test\n",
            "finished fitting\n",
            "finished transform train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:09<00:09,  1.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform validation\n",
            "finished transform test\n",
            "finished fitting\n",
            "finished transform train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [00:11<00:06,  1.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform validation\n",
            "finished transform test\n",
            "finished fitting\n",
            "finished transform train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [00:12<00:04,  1.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform validation\n",
            "finished transform test\n",
            "finished fitting\n",
            "finished transform train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [00:13<00:03,  1.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform validation\n",
            "finished transform test\n",
            "finished fitting\n",
            "finished transform train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [00:15<00:01,  1.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform validation\n",
            "finished transform test\n",
            "finished fitting\n",
            "finished transform train\n",
            "finished transform validation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:18<00:00,  1.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished transform test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6DdJxSW-EkA"
      },
      "source": [
        "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique()+1,embedding_dim=256)\n",
        "                       for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
        "                      for feat in dense_features]\n",
        "\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_q0vRVy-FeH"
      },
      "source": [
        "# 3.generate input data for model\n",
        "train_model_input = {name:train[name] for name in feature_names}\n",
        "val_model_input = {name:val[name] for name in feature_names}\n",
        "test_model_input = {name:test[name] for name in feature_names}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKvEwLCp-KfW"
      },
      "source": [
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJmaj6Ei-NId",
        "outputId": "9ac1e344-d6cd-473e-9e43-840de5b4650c"
      },
      "source": [
        "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary',\n",
        "        dnn_dropout=0.3, l2_reg_embedding=0.2, l2_reg_dnn=0.2)\n",
        "model.compile(optimizer=\"adam\", loss=root_mean_squared_error,\n",
        "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC()], )\n",
        "\n",
        "history = model.fit(train_model_input, train[target].values,batch_size=128, epochs=5, verbose=1, validation_data=(val_model_input, val[target].values))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1804/1804 [==============================] - 56s 29ms/step - loss: 5.5433 - root_mean_squared_error: 0.3817 - binary_accuracy: 0.8053 - auc: 0.9182 - val_loss: 0.2553 - val_root_mean_squared_error: 0.2545 - val_binary_accuracy: 0.9332 - val_auc: 0.9791\n",
            "Epoch 2/5\n",
            "1804/1804 [==============================] - 52s 29ms/step - loss: 0.2465 - root_mean_squared_error: 0.2464 - binary_accuracy: 0.9345 - auc: 0.9794 - val_loss: 0.2307 - val_root_mean_squared_error: 0.2298 - val_binary_accuracy: 0.9377 - val_auc: 0.9812\n",
            "Epoch 3/5\n",
            "1804/1804 [==============================] - 53s 29ms/step - loss: 0.2279 - root_mean_squared_error: 0.2278 - binary_accuracy: 0.9376 - auc: 0.9813 - val_loss: 0.2229 - val_root_mean_squared_error: 0.2224 - val_binary_accuracy: 0.9382 - val_auc: 0.9818\n",
            "Epoch 4/5\n",
            "1804/1804 [==============================] - 53s 29ms/step - loss: 0.2226 - root_mean_squared_error: 0.2222 - binary_accuracy: 0.9377 - auc: 0.9817 - val_loss: 0.2196 - val_root_mean_squared_error: 0.2192 - val_binary_accuracy: 0.9392 - val_auc: 0.9820\n",
            "Epoch 5/5\n",
            "1804/1804 [==============================] - 52s 29ms/step - loss: 0.2200 - root_mean_squared_error: 0.2193 - binary_accuracy: 0.9382 - auc: 0.9821 - val_loss: 0.2184 - val_root_mean_squared_error: 0.2176 - val_binary_accuracy: 0.9392 - val_auc: 0.9821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgTHtmih-p3e",
        "outputId": "d7bc7baf-94d0-48a3-e2aa-2d240679d3ce"
      },
      "source": [
        "pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
        "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test LogLoss 0.1655\n",
            "test AUC 0.9823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWOxDsMZioJn"
      },
      "source": [
        "# Todo: Utizling DeepFM and expand it's use by applying it with different data such as Criteo or Avazu.\n",
        "Notably, we did not perform k-fold and any cleansing of data. \n",
        "\n",
        "Implement 5-fold within this experiments and make sure to use for sparse and dense features.\n",
        "\n",
        "More info regarding DeepFM can be found at:\n",
        "* https://github.com/shenweichen/DeepCTR\n",
        "* https://deepctr-doc.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djm9toSf-std"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}